{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9578d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchvision import transforms # For standard image transforms \n",
    "import torch.nn as nn\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor # For ViT model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b42280bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "TRAIN_FOLDER = './train'\n",
    "TEST_FOLDER = './test' # Assuming you have a separate test folder\n",
    "IMAGE_SIZE = (224, 224) # Standard input size for many ViTs/CNNs\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10 \n",
    "\n",
    "# Regex pattern for filenames (updated to match your example format exactly) \n",
    "# s2_CropType_ID_UniqueID_YYYY_MM.tif\n",
    "PATTERN = re.compile(r\"s2_([a-zA-Z]+)_ID_([a-zA-Z0-9]+)_(\\d{4})_(\\d{2})\\.tif\")\n",
    "\n",
    "# --- Step 1: Data Collection & Label Encoding ---\n",
    "def collect_image_info(folder_path, is_train=True):\n",
    "    data_info = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        match = PATTERN.match(filename)\n",
    "        if match:\n",
    "            crop_type, loc_id, year, month = match.groups()\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # For training data, skip \"Unknown\" labels\n",
    "            if is_train and crop_type == \"Unknown\":\n",
    "                continue\n",
    "\n",
    "            data_info.append({\n",
    "                'filename': file_path,\n",
    "                'crop_type': crop_type,\n",
    "                'location_id': loc_id,\n",
    "                'year': int(year),\n",
    "                'month': int(month)\n",
    "            })\n",
    "    return pd.DataFrame(data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b557189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Crop Classes: ['Cocoa' 'Palm' 'Rubber']\n",
      "Number of Classes: 3\n",
      "\n",
      "Train samples: 5941\n",
      "Validation samples: 1492\n",
      "Test samples: 2201\n"
     ]
    }
   ],
   "source": [
    "train_df_raw = collect_image_info(TRAIN_FOLDER, is_train=True)\n",
    "test_df_raw = collect_image_info(TEST_FOLDER, is_train=False)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train_df_raw['crop_type']) \n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Detected Crop Classes: {label_encoder.classes_}\")\n",
    "print(f\"Number of Classes: {num_classes}\") \n",
    "\n",
    "train_df_raw['encoded_label'] = label_encoder.transform(train_df_raw['crop_type'])\n",
    "# For test_df_raw, we'll keep 'crop_type' as is (will contain 'Unknown' or actual labels if available for evaluation)\n",
    "\n",
    "unique_train_locs = train_df_raw['location_id'].unique()\n",
    "train_locs, val_locs = train_test_split(unique_train_locs, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = train_df_raw[train_df_raw['location_id'].isin(train_locs)].reset_index(drop=True)\n",
    "val_df = train_df_raw[train_df_raw['location_id'].isin(val_locs)].reset_index(drop=True)\n",
    "test_df = test_df_raw.reset_index(drop=True) # test_df_raw is already your final test set\n",
    "\n",
    "print(f\"\\nTrain samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed13bee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>crop_type</th>\n",
       "      <th>location_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./train\\s2_Cocoa_ID_0bCYpY_2024_01.tif</td>\n",
       "      <td>Cocoa</td>\n",
       "      <td>0bCYpY</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./train\\s2_Cocoa_ID_0bCYpY_2024_02.tif</td>\n",
       "      <td>Cocoa</td>\n",
       "      <td>0bCYpY</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./train\\s2_Cocoa_ID_0bCYpY_2024_03.tif</td>\n",
       "      <td>Cocoa</td>\n",
       "      <td>0bCYpY</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./train\\s2_Cocoa_ID_0bCYpY_2024_04.tif</td>\n",
       "      <td>Cocoa</td>\n",
       "      <td>0bCYpY</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./train\\s2_Cocoa_ID_0bCYpY_2024_07.tif</td>\n",
       "      <td>Cocoa</td>\n",
       "      <td>0bCYpY</td>\n",
       "      <td>2024</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 filename crop_type location_id  year  month  \\\n",
       "0  ./train\\s2_Cocoa_ID_0bCYpY_2024_01.tif     Cocoa      0bCYpY  2024      1   \n",
       "1  ./train\\s2_Cocoa_ID_0bCYpY_2024_02.tif     Cocoa      0bCYpY  2024      2   \n",
       "2  ./train\\s2_Cocoa_ID_0bCYpY_2024_03.tif     Cocoa      0bCYpY  2024      3   \n",
       "3  ./train\\s2_Cocoa_ID_0bCYpY_2024_04.tif     Cocoa      0bCYpY  2024      4   \n",
       "4  ./train\\s2_Cocoa_ID_0bCYpY_2024_07.tif     Cocoa      0bCYpY  2024      7   \n",
       "\n",
       "   encoded_label  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c6200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBandImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None, is_train=True, label_encoder=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.dataframe.iloc[idx]['filename'] \n",
    "        raw_label = self.dataframe.iloc[idx]['crop_type']\n",
    "        location_id = self.dataframe.iloc[idx]['location_id'] \n",
    "\n",
    "        with rasterio.open(file_path) as src:\n",
    "            image_data = src.read().astype(np.float32) \n",
    "\n",
    "            self.num_channels = src.count \n",
    "\n",
    "\n",
    "            image_tensor = torch.from_numpy(image_data) # Shape: (C, H, W)\n",
    "\n",
    "            if self.transform:\n",
    "                image_tensor = self.transform(image_tensor)\n",
    "\n",
    "        # Handle labels\n",
    "        if self.is_train:\n",
    "            label = self.label_encoder.transform([raw_label])[0] # Encode to numerical ID\n",
    "        else:\n",
    "            label = raw_label \n",
    "\n",
    "        return image_tensor, label, file_path, location_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e24ab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_num_bands = rasterio.open(train_df.iloc[0]['filename']).count # Get band count from one image\n",
    "DUMMY_MEAN = [0.5] * example_num_bands # Replace with actual mean for each band\n",
    "DUMMY_STD = [0.5] * example_num_bands  # Replace with actual std for each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b53947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBandToTensorAndNormalize:\n",
    "    def __init__(self, target_size, mean, std):\n",
    "        self.resize = transforms.Resize(target_size)\n",
    "        self.normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "    def __call__(self, img_tensor):\n",
    "        # Assumes img_tensor is (C, H, W) float32\n",
    "        img_tensor = self.resize(img_tensor) # Resizes (H, W) for all C\n",
    "        img_tensor = self.normalize(img_tensor)\n",
    "        return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e626ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    MultiBandToTensorAndNormalize(IMAGE_SIZE, DUMMY_MEAN, DUMMY_STD),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    MultiBandToTensorAndNormalize(IMAGE_SIZE, DUMMY_MEAN, DUMMY_STD),\n",
    "])\n",
    "\n",
    "# Create Dataset and DataLoader instances\n",
    "train_dataset = MultiBandImageDataset(train_df, transform=train_transform, is_train=True, label_encoder=label_encoder)\n",
    "val_dataset = MultiBandImageDataset(val_df, transform=val_test_transform, is_train=True, label_encoder=label_encoder)\n",
    "test_dataset = MultiBandImageDataset(test_df, transform=val_test_transform, is_train=False)\n",
    "\n",
    "# Reduce number of workers and enable pin_memory for faster data loading \n",
    "num_workers = min(4, os.cpu_count())\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=False, persistent_workers=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=False, persistent_workers=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=False, persistent_workers=True)\n",
    "\n",
    "# Verify a batch\n",
    "try:\n",
    "    for images, labels, paths in train_loader:\n",
    "        print(f\"\\nBatch of images shape: {images.shape}\") # (batch_size, channels, height, width)\n",
    "        print(f\"Batch of labels shape: {labels.shape}\")   # (batch_size)\n",
    "        print(f\"First image path in batch: {paths[0]}\")\n",
    "        first_image_bands = images.shape[1]\n",
    "        break \n",
    "except Exception as e:\n",
    "    print(f\"Error loading batch: {e}\")\n",
    "    print(\"Check your MultiBandImageDataset __getitem__ method and transforms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8fd129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "model_name = \"timm/mobilenetv3_small_100.lamb_in1k\"\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_classes,\n",
    "    ignore_mismatched_sizes=True # Allows adapting the classifier head and input layer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c85d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_image_bands != 3: # If your TIFFs are not standard RGB (3 channels)\n",
    "    original_conv_layer = model.vit.embeddings.patch_embeddings.projection\n",
    "    new_conv_layer = nn.Conv2d(\n",
    "        in_channels=first_image_bands, # Set to the actual number of bands in your TIFFs\n",
    "        out_channels=original_conv_layer.out_channels,\n",
    "        kernel_size=original_conv_layer.kernel_size,\n",
    "        stride=original_conv_layer.stride,\n",
    "        padding=original_conv_layer.padding,\n",
    "        bias=True # Keep bias as original\n",
    "    )\n",
    "    # Optionally, you could initialize the new_conv_layer weights from the original\n",
    "    # by averaging across the input channels, or simple random initialization is fine\n",
    "    # for fine-tuning.\n",
    "    model.vit.embeddings.patch_embeddings.projection = new_conv_layer\n",
    "    print(f\"Adjusted ViT input channels from 3 to {first_image_bands}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c951d63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_predictions = []\n",
    "test_actual_labels = [] # To store actual labels from test_df for evaluation\n",
    "test_image_paths = []\n",
    "test_location_ids = [] # <--- New list to store location IDs\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, paths, loc_ids in test_loader: # <--- Unpack loc_ids here\n",
    "        images = images.to(device)\n",
    "        outputs = model(pixel_values=images)\n",
    "        logits = outputs.logits\n",
    "        predicted_classes_encoded = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "\n",
    "        test_predictions.extend(label_encoder.inverse_transform(predicted_classes_encoded))\n",
    "        test_actual_labels.extend(labels)\n",
    "        test_image_paths.extend(paths)\n",
    "        test_location_ids.extend(loc_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1b8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    # 'image_path': test_image_paths,\n",
    "    'location_id': test_location_ids, # <--- Add the new column\n",
    "    # 'actual_label': test_actual_labels, # This will include 'Unknown' for blind test set\n",
    "    'predicted_label': test_predictions\n",
    "})\n",
    "print(\"\\nSample Test Predictions:\")\n",
    "print(results_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cotedivore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
